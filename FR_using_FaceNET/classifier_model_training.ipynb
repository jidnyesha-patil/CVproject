{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e70fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\rushi\\anaconda3\\envs\\python364\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import mtcnn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "# load the model\n",
    "model = load_model('facenet_keras.h5',compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479e06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(pix,detector):\n",
    "    results = detector.detect_faces(pix)\n",
    "    if results:\n",
    "        x1, y1, width, height = results[0]['box']\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        face = pix1[y1:y2, x1:x2]\n",
    "        face = cv2.resize(face,(160,160))\n",
    "        return face\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b09f2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['amey', 'anamika', 'gauri', 'piyush', 'richa', 'riddhi'], 'Count': [22, 23, 24, 27, 21, 22]}\n"
     ]
    }
   ],
   "source": [
    "doc1 = {\"Name\":[] , \"Count\":[]}\n",
    "path = 'C:\\\\Users\\\\rushi\\\\Documents\\\\CV_project\\\\Intro_DB\\\\'\n",
    "name_list = os.listdir(path)\n",
    "for name in name_list:\n",
    "    doc1[\"Name\"].append(name)\n",
    "    new_path = path + name + '\\\\'\n",
    "    n = os.listdir(new_path)\n",
    "    doc1[\"Count\"].append(len(n))\n",
    "    \n",
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab67ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function _make_execution_function.<locals>.distributed_function at 0x000002048216DAE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "doc2 = {\"label\":[],\"images\":[]}\n",
    "path = \"Intro_DB\\\\\"\n",
    "detector = mtcnn.MTCNN()\n",
    "for length in range(len(doc1[\"Name\"])):\n",
    "    name = doc1[\"Name\"][length]\n",
    "    c = doc1[\"Count\"][length]\n",
    "    new_path = path + name + \"\\\\\" + name\n",
    "    for i in range(c):\n",
    "        new_path1 = new_path + str(i+1) + \".jpg\"\n",
    "        img1 = cv2.imread(new_path1)\n",
    "        pix1 = np.asarray(img1)\n",
    "        face = face_detection(pix1,detector)\n",
    "        if type(face) != type(None): \n",
    "            doc2['label'].append(name)\n",
    "            doc2['images'].append(face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b4aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'amey', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'anamika', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'gauri', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'piyush', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'richa', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi', 'riddhi']\n"
     ]
    }
   ],
   "source": [
    "print(doc2[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f978ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.array(doc2[\"label\"])\n",
    "images = np.array(doc2[\"images\"])\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(\n",
    "images, label, test_size=0.9, random_state=42)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1716af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the face embedding for one face\n",
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    samples = np.expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd17919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 128)\n",
      "(111, 128)\n"
     ]
    }
   ],
   "source": [
    "# convert each face in the train set to an embedding\n",
    "newTrainX = list()\n",
    "for face_pixels in trainX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTrainX.append(embedding)\n",
    "newTrainX = np.asarray(newTrainX)\n",
    "print(newTrainX.shape)\n",
    "# convert each face in the test set to an embedding\n",
    "newTestX = list()\n",
    "for face_pixels in testX:\n",
    "    embedding = get_embedding(model, face_pixels)\n",
    "    newTestX.append(embedding)\n",
    "newTestX = np.asarray(newTestX)\n",
    "print(newTestX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18a9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: train=100.000, test=67.568\n"
     ]
    }
   ],
   "source": [
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "trainX = in_encoder.transform(newTrainX)\n",
    "testX = in_encoder.transform(newTestX)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(trainy)\n",
    "trainy = out_encoder.transform(trainy)\n",
    "testy = out_encoder.transform(testy)\n",
    "# fit model\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "model.fit(trainX, trainy)\n",
    "# predict\n",
    "yhat_train = model.predict(trainX)\n",
    "yhat_test = model.predict(testX)\n",
    "# score\n",
    "score_train = accuracy_score(trainy, yhat_train)\n",
    "score_test = accuracy_score(testy, yhat_test)\n",
    "# summarize\n",
    "print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a561a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09007528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
